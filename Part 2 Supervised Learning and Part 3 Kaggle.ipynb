{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Supervised Learning and Part 3 Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "import operator\n",
    "import time\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA    \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# !pip install mca\n",
    "# import mca\n",
    "import chardet\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: scipy in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from lightgbm) (1.2.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from lightgbm) (0.20.3)\n",
      "Requirement already satisfied: numpy in /Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from lightgbm) (1.16.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharva/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "# azdias = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_AZDIAS_052018.csv', sep=';', dtype=str)\n",
    "# customers = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_CUSTOMERS_052018.csv', sep=';', dtype=str)\n",
    "azdias = pd.read_csv('Udacity_AZDIAS_052018.csv', sep=';', dtype=str)\n",
    "customers = pd.read_csv('Udacity_CUSTOMERS_052018.csv', sep=';', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')\n",
    "training = pd.read_csv('Udacity_MAILOUT_052018_TRAIN.csv', sep=';', dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1763</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1771</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1783</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR AGER_TYP AKT_DAT_KL ALTER_HH ALTER_KIND1 ALTER_KIND2 ALTER_KIND3  \\\n",
       "0  1763        2          1        8         NaN         NaN         NaN   \n",
       "1  1771        1          4       13         NaN         NaN         NaN   \n",
       "2  1776        1          1        9         NaN         NaN         NaN   \n",
       "3  1460        2          1        6         NaN         NaN         NaN   \n",
       "4  1783        2          1        9         NaN         NaN         NaN   \n",
       "\n",
       "  ALTER_KIND4 ALTERSKATEGORIE_FEIN ANZ_HAUSHALTE_AKTIV  ... VK_DHT4A  \\\n",
       "0         NaN                    8                  15  ...        5   \n",
       "1         NaN                   13                   1  ...        1   \n",
       "2         NaN                    7                   0  ...        6   \n",
       "3         NaN                    6                   4  ...        8   \n",
       "4         NaN                    9                  53  ...        2   \n",
       "\n",
       "  VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP RESPONSE  \\\n",
       "0          2       1              6              9        3        3        0   \n",
       "1          2       1              4              9        7        1        0   \n",
       "2          4       2            NaN              9        2        3        0   \n",
       "3         11      11              6              9        1        3        0   \n",
       "4          2       1              6              9        3        3        0   \n",
       "\n",
       "  ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         2                    4  \n",
       "1         2                    3  \n",
       "2         1                    4  \n",
       "3         2                    4  \n",
       "4         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_cleaned = azdias.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_info = pd.read_csv(\"features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>information_level</th>\n",
       "      <th>type</th>\n",
       "      <th>missing_or_unknown</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGER_TYP</td>\n",
       "      <td>person</td>\n",
       "      <td>categorical</td>\n",
       "      <td>[-1,0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTER_HH</td>\n",
       "      <td>household</td>\n",
       "      <td>interval</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALTERSKATEGORIE_GROB</td>\n",
       "      <td>person</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>[-1,0,9]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANREDE_KZ</td>\n",
       "      <td>person</td>\n",
       "      <td>categorical</td>\n",
       "      <td>[-1,0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANZ_HAUSHALTE_AKTIV</td>\n",
       "      <td>building</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              attribute information_level         type missing_or_unknown  \\\n",
       "0              AGER_TYP            person  categorical             [-1,0]   \n",
       "1              ALTER_HH         household     interval                [0]   \n",
       "2  ALTERSKATEGORIE_GROB            person      ordinal           [-1,0,9]   \n",
       "3             ANREDE_KZ            person  categorical             [-1,0]   \n",
       "4   ANZ_HAUSHALTE_AKTIV          building      numeric                [0]   \n",
       "\n",
       "  Comment  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in feat_info.iterrows():\n",
    "    attribute, information_level, var_type, missing, comment = row\n",
    "    if attribute in azdias_cleaned.columns:\n",
    "        values = missing.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")\n",
    "        replacement = {}\n",
    "        for value in values:\n",
    "            value = value.strip()\n",
    "            replacement[value] = None\n",
    "        azdias_cleaned.loc[:, attribute].replace(replacement, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sl_data(df, azdias_cleaned=azdias_cleaned):\n",
    "    \"\"\"\n",
    "    Cleans the data frame and performs necessary replacements and transformations.\n",
    "    Input:\n",
    "    - df: DataFrame to be cleaned\n",
    "    Output:\n",
    "    - df: cleaned and transformed DataFrame\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    cat_cols = []\n",
    "    num_cols = []\n",
    "    for index, row in feat_info.iterrows():\n",
    "        attribute, information_level, var_type, missing, comment = row\n",
    "        if var_type in [\"interval\", \"categorical\"]:\n",
    "            cat_cols.append(attribute)\n",
    "        elif var_type in [\"ordinal\", \"numeric\"]:\n",
    "            num_cols.append(attribute)\n",
    "        if attribute in df.columns:\n",
    "            values = missing.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\")\n",
    "            replacement = {}\n",
    "            for value in values:\n",
    "                value = value.strip()\n",
    "                replacement[value] = None\n",
    "            df.loc[:, attribute].replace(replacement, inplace=True)\n",
    "#     df.replace({\"-1\": None, 'X': None, 'XX': None}, inplace=True)\n",
    "    recode = ['D19_BANKEN_DATUM', 'D19_BANKEN_OFFLINE_DATUM',\n",
    "       'D19_BANKEN_ONLINE_DATUM', 'D19_GESAMT_DATUM',\n",
    "       'D19_GESAMT_OFFLINE_DATUM', 'D19_GESAMT_ONLINE_DATUM',\n",
    "       'D19_TELKO_DATUM', 'D19_TELKO_OFFLINE_DATUM',\n",
    "       'D19_TELKO_ONLINE_DATUM', 'D19_VERSAND_DATUM',\n",
    "       'D19_VERSAND_OFFLINE_DATUM', 'D19_VERSAND_ONLINE_DATUM',\n",
    "       'D19_VERSI_DATUM', 'D19_VERSI_OFFLINE_DATUM',\n",
    "       'D19_VERSI_ONLINE_DATUM']\n",
    "    df[recode] = df[recode].replace(\"10\", \"0\")\n",
    "    \n",
    "#     df_for_cls = df[common_cols].copy()\n",
    "\n",
    "    to_drop = [\"LNR\", 'AGER_TYP', 'ALTER_HH', 'ALTER_KIND1', 'ALTER_KIND2', 'ALTER_KIND3',\n",
    "       'ALTER_KIND4', 'EXTSEL992', 'GEBURTSJAHR', 'HH_DELTA_FLAG',\n",
    "       'KBA05_BAUMAX', 'KK_KUNDENTYP', 'KKK', 'REGIOTYP', 'TITEL_KZ', 'CAMEO_DEU_2015',\n",
    "       'W_KEIT_KIND_HH']\n",
    "    df_for_cls = df.drop(columns=[col for col in to_drop if col in df.columns])\n",
    "    df_for_cls = df_for_cls[[col for col in azdias_cleaned.columns if col in df_for_cls.columns]]\n",
    "    for col in df_for_cls.columns:\n",
    "        df_for_cls.loc[:, col] = df_for_cls[col].fillna(value=azdias_cleaned[col].mode()[0])   \n",
    "    numbers = [str(x) for x in range(100)]\n",
    "    \n",
    "    for col in df_for_cls.columns:\n",
    "        level = 0\n",
    "        for value in df_for_cls[col].unique():\n",
    "            if value not in numbers:\n",
    "                df_for_cls.loc[df_for_cls[col] == value, col] = level\n",
    "                level += 1\n",
    "\n",
    "    df_for_cls = df_for_cls.astype(float)\n",
    "    return df_for_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, input_array, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, input_array, y=None):\n",
    "        return clean_sl_data(df=input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training.drop(columns=[\"RESPONSE\"])\n",
    "Y = training[\"RESPONSE\"].astype(int)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline = Pipeline([   \n",
    "            (\"cleaner\", DataCleaner()),\n",
    "            (\"clf\", DecisionTreeClassifier())\n",
    "    \n",
    "])\n",
    "param_grid = {              \n",
    "              'clf__max_depth': [10, None],\n",
    "            'clf__min_samples_leaf': [1, 3]\n",
    "            }\n",
    "cv_pipeline = GridSearchCV(estimator=clf_pipeline, param_grid=param_grid, scoring='roc_auc', cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_pipeline.best_score_)\n",
    "print(cv_pipeline.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_proba = cv_pipeline.predict_proba(X_test)                 \n",
    "auc = roc_auc_score(Y_test, Y_pred_proba[:, 1])\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Decision Tree Classifier serves as good starting point in choosing the classifier, there is a significant room of improvement in the ROC AUC with more sophisticated algorithm. As our current dataset is highly imbalanced, it is a shortcoming of Decision Tree Classifier that a single DTC can't handle highly imbalanced datasets very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to explore an ensemble learning classifier named LightGBM based on Gradient Boosting algorithm, which is recently become widely accessible to scientific community through open source library called LightGBM made available by Microsoft. It can take use of GPU for faster training time and it can also handle imbalanced datasets like the current one very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': 'binary',\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0,\n",
       " 'metric': 'auc'}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = lgb.LGBMClassifier(objective='binary', metric='auc', random_state=42)\n",
    "lgbm_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline = Pipeline([   \n",
    "            (\"cleaner\", DataCleaner()),\n",
    "            (\"clf\", lgbm_clf)\n",
    "    \n",
    "])\n",
    "param_grid = {'clf__boosting_type': ['gbdt', 'dart'],              \n",
    "              'clf__num_iterations': [200],\n",
    "              'clf__num_leaves': [65],\n",
    "                'clf__learning_rate': [0.01],}\n",
    "cv_pipeline = GridSearchCV(estimator=clf_pipeline, param_grid=param_grid, scoring='roc_auc', cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cv_pipeline.best_estimator_, open('lgbm_model.pkl', 'wb'))\n",
    "pickle.dump(cv_pipeline, open('best_pipeline.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cleaner', DataCleaner()), ('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        metric='auc', min_child_samples=20, min_child_weight=0.001,\n",
       "        ...  reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__learning_rate': [0.01], 'clf__num_iterations': [200], 'clf__boosting_type': ['gbdt'], 'clf__num_leaves': [62], 'clf__random_state': [42]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728555132683\n",
      "Pipeline(memory=None,\n",
      "     steps=[('cleaner', DataCleaner()), ('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='split', learning_rate=0.01, max_depth=-1,\n",
      "        metric='auc', min_child_samples=20, min_child_weight=0.001,\n",
      "        min_split_gain=0.0, n_estimators=100...0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0))])\n"
     ]
    }
   ],
   "source": [
    "print(cv_pipeline.best_score_)\n",
    "print(cv_pipeline.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = cv_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10741\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_pred).loc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10594\n",
       "1      147\n",
       "Name: RESPONSE, dtype: int64"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=Y_test, y_pred=Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74499299436595479"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_proba = cv_pipeline.predict_proba(X_test)                 \n",
    "auc = roc_auc_score(Y_test, Y_pred_proba[:, 1])\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that LightGBM is giving impressive performance on local test in terms of high value of ROC AUC. To verify the robustness of this algorithm to be fit for this application, we can do cross validation test on a little larger number of splits and on more independent datasets. We can also increase the number of parameters against which we test this algorithm using GridSearch to even further improve its performance by finding the best values for hyper parameters. We can further assure robustness by checking that the performance of the LightGBM remains relatively high, no matter what value of `random_state` parameter is set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training time for LightGBM is longer on CPU. It can be expedited using GPU optimized version of the library by compiling and building it using graphics card related libraries and build options. Other non-linear classifiers like SVM and Neural Netowrks can be tested to see if they provide relative performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_proba_final = cv_pipeline.predict_proba(mailout_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.DataFrame({\"LNR\": list(mailout_test[\"LNR\"]), \"RESPONSE\": list(Y_pred_proba_final[:, 1])})\n",
    "kaggle.to_csv(\"kaggle1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1754</td>\n",
       "      <td>0.013365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1770</td>\n",
       "      <td>0.012894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465</td>\n",
       "      <td>0.003863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1470</td>\n",
       "      <td>0.003685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1478</td>\n",
       "      <td>0.009237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  RESPONSE\n",
       "0  1754  0.013365\n",
       "1  1770  0.012894\n",
       "2  1465  0.003863\n",
       "3  1470  0.003685\n",
       "4  1478  0.009237"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"kaggle1.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
